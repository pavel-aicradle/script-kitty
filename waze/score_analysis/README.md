
### Score Histograms

Our score was generated by passing isochron fraction (current area / baseline area) through this funciton of Franz's devising.

![](franz%20score%20function.png)

I originally suggested using a function that instead would place an equal number of points in each decile, so if a lot of points had a fraction around 0.7 or whatever, those would get separated out a bit, and if few points had scores in 0-0.4, then that domain would get compressed a bit. We didn't have the analysis at the time to be able to come up with a function that would bucket points evenly, but when we got an established Kafka feed I was eager to do the analysis.

<img src="Screen%20Shot%202020-04-22%20at%2012.42.38%20PM.png" width="250">

Splitting the above out into the scores due to macro and micro points:

<img src="Screen%20Shot%202020-04-22%20at%2012.44.43%20PM.png" width=250>
<img src="Screen%20Shot%202020-04-22%20at%2012.44.17%20PM.png" width=250>

### Score Subsampling

With a limited budget of isochron requests to TomTom each minute, we couldn't reasonably query all the points of interest we wanted to in order to generate our traffic/social distance scores. Given a limited budget per county, how well would our score reflect the real score?

This is a classic [subsampling problem](https://en.wikipedia.org/wiki/Sampling_distribution), and the answer is given as subsample scatter ∝ 1 / √(n), where n is the subsample size. I wrote some code to basically do some random subsampling and simulate that process to figure out how much this would hurt us.

<img src="Screen%20Shot%202020-04-22%20at%2012.12.25%20PM.png" width=250>
<img src="Screen%20Shot%202020-04-22%20at%2012.14.31%20PM.png" width=250>




